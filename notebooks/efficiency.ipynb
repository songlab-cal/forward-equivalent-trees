{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9cc199-440c-47f5-a6b1-63c57919618d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Any\n",
    "import itertools\n",
    "import json\n",
    "from typing import Optional\n",
    "import hashlib\n",
    "\n",
    "from ete3.coretype.tree import TreeError\n",
    "from scipy.stats import mannwhitneyu, kstest\n",
    "import pathlib\n",
    "\n",
    "import bdms\n",
    "from bdms import mutators, poisson\n",
    "import ete3\n",
    "import modulators\n",
    "import my_bdms\n",
    "import utils\n",
    "\n",
    "import traceback\n",
    "\n",
    "# The modulator class and poisson class will throw divide by zero warnings. \n",
    "# It is correct to have these evaluation to np.inf, so warnings are suppressed.\n",
    "np.seterr(divide=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeddfa5",
   "metadata": {},
   "source": [
    "## Define simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_tree(\n",
    "    seed: int,\n",
    "    state_space: my_bdms.ListOfHashables,\n",
    "    sampling_probability: float,\n",
    "    init_dist: np.ndarray,\n",
    "    birth_process: poisson.Process,\n",
    "    death_process: poisson.Process,\n",
    "    mutation_process: poisson.Process,\n",
    "    mutator: mutators.Mutator,\n",
    "    t_max: float,\n",
    "    tree_id: Optional[int] = None,\n",
    "    t_min: float = 0.0,\n",
    "    do_prune: bool = True,\n",
    "    min_survivors: int = 1,\n",
    "    capacity: int = 10000,\n",
    "):\n",
    "    if tree_id is None:\n",
    "        tree_id = 1\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        tree = bdms.TreeNode()\n",
    "        tree.t = t_min\n",
    "        tree.state = rng.choice(state_space, p=init_dist)\n",
    "        tree.evolve(\n",
    "            t_max,\n",
    "            birth_process=birth_process,\n",
    "            death_process=death_process,\n",
    "            mutation_process=mutation_process,\n",
    "            mutator=mutator,\n",
    "            min_survivors=min_survivors,\n",
    "            capacity=capacity,\n",
    "            birth_mutations=False,\n",
    "            seed=rng,\n",
    "        )\n",
    "        unpruned_tree_size = utils.tree_size(tree)\n",
    "        unpruned_tree_leaf_count = len(tree)\n",
    "\n",
    "        if do_prune:\n",
    "            tree.sample_survivors(\n",
    "                p=sampling_probability\n",
    "            )  ## WARNING: does not do phenotype specific sampling.\n",
    "            if sum([node.event == \"sampling\" for node in tree.traverse()]) > 0:\n",
    "                tree.prune_unsampled()\n",
    "            else:\n",
    "                tree = None\n",
    "\n",
    "        end_time = time.time()\n",
    "        is_error = False\n",
    "\n",
    "    except TreeError as e:\n",
    "        tree = None\n",
    "        unpruned_tree_size = 0\n",
    "        unpruned_tree_leaf_count = 0\n",
    "        end_time = time.time()\n",
    "        is_error = True\n",
    "\n",
    "    return {\n",
    "        \"tree\": tree,\n",
    "        \"tree_id\": tree_id,\n",
    "        \"seed\": seed,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "        \"unpruned_tree_size\": unpruned_tree_size,\n",
    "        \"unpruned_tree_leaf_count\": unpruned_tree_leaf_count,\n",
    "        \"is_error\": is_error,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    tree_info: dict[str, Any],\n",
    "    tree_metric_info: list[str],\n",
    "    clade_metric_info: list[str],\n",
    "):\n",
    "    tree_df = pd.DataFrame()\n",
    "    clade_df = pd.DataFrame()\n",
    "\n",
    "    seed = tree_info[\"seed\"]\n",
    "    tree_id = tree_info[\"tree_id\"]\n",
    "    tree = tree_info[\"tree\"]\n",
    "    tree_df.loc[tree_id, \"tree_id\"] = tree_info[\"tree_id\"]\n",
    "    tree_df.loc[tree_id, \"seed\"] = tree_info[\"seed\"]\n",
    "    tree_df.loc[tree_id, \"unpruned tree size\"] = tree_info[\"unpruned_tree_size\"]\n",
    "    tree_df.loc[tree_id, \"unpruned tree leaf count\"] = tree_info[\n",
    "        \"unpruned_tree_leaf_count\"\n",
    "    ]\n",
    "    tree_df.loc[tree_id, \"pruned tree size\"] = (\n",
    "        utils.tree_size(tree) if tree is not None else 0\n",
    "    )\n",
    "    tree_df.loc[tree_id, \"pruned tree leaf count\"] = (\n",
    "        len(tree) if tree is not None else 0\n",
    "    )\n",
    "    tree_df.loc[tree_id, \"time\"] = tree_info[\"end_time\"] - tree_info[\"start_time\"]\n",
    "    tree_df.loc[tree_id, \"is_error\"] = int(tree_info[\"is_error\"])\n",
    "\n",
    "    if tree is not None:\n",
    "        tree = tree_info[\"tree\"]\n",
    "\n",
    "        for _, info in tree_metric_info.items():  # iterate over metrics\n",
    "            for fnc_arg in info[\"fnc_args\"]:\n",
    "                data = info[\"fnc\"](tree, **fnc_arg)\n",
    "                for key in info[\"result_keys\"]:\n",
    "                    tree_df.loc[\n",
    "                        tree_id,\n",
    "                        info[\"col_name\"](**fnc_arg, **{info[\"result_key_name\"]: key}),\n",
    "                    ] = (\n",
    "                        data[key] if key in data else info[\"default_value\"]\n",
    "                    )\n",
    "\n",
    "        for _, info in clade_metric_info.items():  # iterate over metrics\n",
    "            for fnc_arg in info[\"fnc_args\"]:\n",
    "                data = info[\"fnc\"](tree, **fnc_arg)\n",
    "                clade_df = pd.concat(\n",
    "                    [\n",
    "                        clade_df,\n",
    "                        pd.DataFrame(\n",
    "                            {\n",
    "                                \"tree_id\": [tree_id] * len(data),\n",
    "                                \"metric\": [info[\"metric_name\"]] * len(data),\n",
    "                                \"phenotype\": [clade[\"phenotype\"] for clade in data],\n",
    "                                \"value\": [clade[\"value\"] for clade in data],\n",
    "                            }\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    return tree_df, clade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5511fe",
   "metadata": {},
   "source": [
    "Specs for different simulation types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_type_no_death_specs = [\n",
    "    {\n",
    "        \"state_space\": [1],\n",
    "        \"sampling_probability\": rho,\n",
    "        \"init_dist\": np.array([1.0]),\n",
    "        \"birth_rates\": np.array([1.0]),\n",
    "        \"death_rates\": np.array([0.0]),\n",
    "        \"mutation_rates\": np.array([0.0]),\n",
    "        \"transition_matrix\": np.array([[1.0]]),\n",
    "        \"t_min\": 0.0,\n",
    "        \"t_max\": 5.0,\n",
    "        \"mode\": mode,\n",
    "        \"min_survivors\": 1,\n",
    "        \"capacity\": 10000,\n",
    "        \"dt\": 0.01,\n",
    "        \"save_tree\": False,\n",
    "        \"tag\": f\"single_type_no_death_rho{int(10*rho)}\",\n",
    "        \"directory\": \"data/single_type_no_death\",\n",
    "        \"N_trees\": 1000,\n",
    "    }\n",
    "    for rho, mode in itertools.product(np.linspace(0.1, 1.0, 10), [\"full\", \"FE\"])\n",
    "]\n",
    "\n",
    "single_type_w_death_specs = [\n",
    "    {\n",
    "        \"state_space\": [1],\n",
    "        \"sampling_probability\": rho,\n",
    "        \"init_dist\": np.array([1.0]),\n",
    "        \"birth_rates\": np.array([1.0]),\n",
    "        \"death_rates\": np.array([1.0]),\n",
    "        \"mutation_rates\": np.array([0.0]),\n",
    "        \"transition_matrix\": np.array([[1.0]]),\n",
    "        \"t_min\": 0.0,\n",
    "        \"t_max\": 10,\n",
    "        \"mode\": mode,\n",
    "        \"min_survivors\": 1,\n",
    "        \"capacity\": 10000,\n",
    "        \"dt\": 0.01,\n",
    "        \"save_tree\": False,\n",
    "        \"tag\": f\"single_type_w_death_rho{int(10*rho)}\",\n",
    "        \"directory\": \"data/single_type_w_death\",\n",
    "        \"N_trees\": 50,\n",
    "    }\n",
    "    for rho, mode in itertools.product(np.linspace(0.1, 1.0, 10), [\"full\", \"FE\"])\n",
    "]\n",
    "\n",
    "multitype_high_birth_fitness_specs = [\n",
    "    {\n",
    "        \"state_space\": [1, 2],\n",
    "        \"sampling_probability\": rho,\n",
    "        \"init_dist\": np.array([1.0, 0.0]),\n",
    "        \"birth_rates\": np.array([0.25, 1.0]),\n",
    "        \"death_rates\": np.array([0.25, 0.25]),\n",
    "        \"mutation_rates\": np.array([0.1, 0.8]),\n",
    "        \"transition_matrix\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n",
    "        \"t_min\": 0.0,\n",
    "        \"t_max\": 20.0,\n",
    "        \"mode\": mode,\n",
    "        \"min_survivors\": 1,\n",
    "        \"capacity\": 15000,\n",
    "        \"dt\": 0.01,\n",
    "        \"save_tree\": False,\n",
    "        \"tag\": f\"multitype_high_birth_fitness_rho{int(10*rho)}\",\n",
    "        \"directory\": \"data/multitype_high_birth_fitness\",\n",
    "        \"N_trees\": 50,\n",
    "    }\n",
    "    for rho, mode in itertools.product(np.linspace(0.1, 1.0, 5), [\"full\", \"FE\"])\n",
    "]\n",
    "\n",
    "multitype_high_birth_fitness_huge_specs = [\n",
    "    {\n",
    "        \"state_space\": [1, 2],\n",
    "        \"sampling_probability\": 1e-9,\n",
    "        \"init_dist\": np.array([0.0, 1.0]),\n",
    "        \"birth_rates\": np.array([0.25, 1.0]),\n",
    "        \"death_rates\": np.array([0.5, 0.25]),\n",
    "        \"mutation_rates\": np.array([0.1, 0.25]),\n",
    "        \"transition_matrix\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n",
    "        \"t_min\": 0.0,\n",
    "        \"t_max\": 47.0,\n",
    "        \"mode\": \"FE\",\n",
    "        \"min_survivors\": 1,\n",
    "        \"capacity\": 15000,\n",
    "        \"dt\": 0.01,\n",
    "        \"save_tree\": True,\n",
    "        \"tag\": f\"multitype_high_birth_fitness_huge\",\n",
    "        \"directory\": \"data/multitype_high_birth_fitness_huge\",\n",
    "        \"N_trees\": 3,\n",
    "    }\n",
    "]\n",
    "\n",
    "multitype_high_birth_fitness_1000_specs = [\n",
    "    {\n",
    "        \"state_space\": [1, 2],\n",
    "        \"sampling_probability\": rho,\n",
    "        \"init_dist\": np.array([1.0, 0.0]),\n",
    "        \"birth_rates\": np.array([0.25, 1.0]),\n",
    "        \"death_rates\": np.array([0.25, 0.25]),\n",
    "        \"mutation_rates\": np.array([0.1, 0.8]),\n",
    "        \"transition_matrix\": np.array([[0.0, 1.0], [1.0, 0.0]]),\n",
    "        \"t_min\": 0.0,\n",
    "        \"t_max\": 20.0,\n",
    "        \"mode\": mode,\n",
    "        \"min_survivors\": 1,\n",
    "        \"capacity\": 15000,\n",
    "        \"dt\": 0.01,\n",
    "        \"save_tree\": False,\n",
    "        \"tag\": f\"multitype_high_birth_fitness_1000_rho{int(10*rho)}\",\n",
    "        \"directory\": \"data/multitype_high_birth_fitness_1000\",\n",
    "        \"N_trees\": 1000,\n",
    "    }\n",
    "    for rho, mode in itertools.product([0.5], [\"full\", \"FE\"])\n",
    "]\n",
    "\n",
    "sim_specs = (\n",
    "    single_type_no_death_specs\n",
    "    + single_type_w_death_specs\n",
    "    + multitype_high_birth_fitness_specs\n",
    "    + multitype_high_birth_fitness_1000_specs\n",
    "    + multitype_high_birth_fitness_huge_specs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8f709",
   "metadata": {},
   "source": [
    "Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TreeNode.prune() missing 1 required positional argument: 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 124\u001b[0m\n\u001b[1;32m    117\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mint\u001b[39m(\n\u001b[1;32m    119\u001b[0m         hashlib\u001b[38;5;241m.\u001b[39msha256(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msim_spec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtree_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mencode())\u001b[38;5;241m.\u001b[39mhexdigest(), \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Simulate tree\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m tree_info \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_tree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling_probability\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_dist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbirth_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbirth_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeath_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeath_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutation_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt_max\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt_min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_survivors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin_survivors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapacity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapacity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m tree_df, clade_df \u001b[38;5;241m=\u001b[39m compute_metrics(\n\u001b[1;32m    142\u001b[0m     tree_info\u001b[38;5;241m=\u001b[39mtree_info,\n\u001b[1;32m    143\u001b[0m     tree_metric_info\u001b[38;5;241m=\u001b[39mtree_metric_info,\n\u001b[1;32m    144\u001b[0m     clade_metric_info\u001b[38;5;241m=\u001b[39mclade_metric_info,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    146\u001b[0m all_trees_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_trees_df, tree_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m, in \u001b[0;36msimulate_tree\u001b[0;34m(seed, state_space, sampling_probability, init_dist, birth_process, death_process, mutation_process, mutator, t_max, tree_id, t_min, do_prune, min_survivors, capacity)\u001b[0m\n\u001b[1;32m     41\u001b[0m tree\u001b[38;5;241m.\u001b[39msample_survivors(\n\u001b[1;32m     42\u001b[0m     p\u001b[38;5;241m=\u001b[39msampling_probability\n\u001b[1;32m     43\u001b[0m )  \u001b[38;5;66;03m## WARNING: does not do phenotype specific sampling.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m([node\u001b[38;5;241m.\u001b[39mevent \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mtraverse()]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TreeNode.prune() missing 1 required positional argument: 'nodes'"
     ]
    }
   ],
   "source": [
    "tree_ids = list(range(10000))\n",
    "verbose = True\n",
    "save_to_file = True\n",
    "\n",
    "for sim_spec in sim_specs:\n",
    "    # Initialize data frames\n",
    "    all_trees_df = pd.DataFrame()\n",
    "    all_clades_df = pd.DataFrame()\n",
    "\n",
    "    # Set up simulators\n",
    "    if sim_spec[\"mode\"] == \"full\":\n",
    "        do_prune = True\n",
    "        birth_process = my_bdms.DiscreteProcess(\n",
    "            sim_spec[\"state_space\"], sim_spec[\"birth_rates\"]\n",
    "        )\n",
    "        death_process = my_bdms.DiscreteProcess(\n",
    "            sim_spec[\"state_space\"], sim_spec[\"death_rates\"]\n",
    "        )\n",
    "        mutation_process = my_bdms.DiscreteProcess(\n",
    "            sim_spec[\"state_space\"], sim_spec[\"mutation_rates\"]\n",
    "        )\n",
    "        mutator = mutators.DiscreteMutator(\n",
    "            state_space=sim_spec[\"state_space\"],\n",
    "            transition_matrix=sim_spec[\"transition_matrix\"],\n",
    "        )\n",
    "\n",
    "    elif sim_spec[\"mode\"] == \"FE\":\n",
    "        do_prune = False\n",
    "        modulator = modulators.FEModulator(\n",
    "            state_space=sim_spec[\"state_space\"],\n",
    "            birth_rates=sim_spec[\"birth_rates\"],\n",
    "            death_rates=sim_spec[\"death_rates\"],\n",
    "            mutation_rates=sim_spec[\"mutation_rates\"],\n",
    "            transition_matrix=sim_spec[\"transition_matrix\"],\n",
    "            rhos=np.full(\n",
    "                len(sim_spec[\"state_space\"]), sim_spec[\"sampling_probability\"]\n",
    "            ),\n",
    "            t_min=sim_spec[\"t_min\"],\n",
    "            t_max=sim_spec[\"t_max\"],\n",
    "            dt=sim_spec[\"dt\"],\n",
    "        )\n",
    "        birth_process = my_bdms.CustomProcess(modulator.λ, modulator.Λ, modulator.Λ_inv)\n",
    "        death_process = poisson.ConstantProcess(0.0)\n",
    "        mutation_process = my_bdms.CustomProcess(\n",
    "            modulator.m, modulator.M, modulator.M_inv\n",
    "        )  # Divide by zero issue?\n",
    "        mutator = my_bdms.CustomMutator(modulator)\n",
    "\n",
    "    # Set up metrics we will compute\n",
    "    tree_metric_info = {\n",
    "        \"subtree_counts\": {\n",
    "            \"fnc\": utils.num_subtrees_by_size,\n",
    "            \"fnc_args\": [{}],\n",
    "            \"result_keys\": list(range(1, 11)),\n",
    "            \"result_key_name\": \"subtree_size\",\n",
    "            \"default_value\": 0,\n",
    "            \"col_name\": lambda subtree_size: f\"subtree_count_w_size={subtree_size}\",\n",
    "        },\n",
    "        \"total_branch_length\": {\n",
    "            \"fnc\": utils.total_branch_length,\n",
    "            \"fnc_args\": [{}],\n",
    "            \"result_keys\": [\"total\"],\n",
    "            \"result_key_name\": \"total\",\n",
    "            \"default_value\": 0,\n",
    "            \"col_name\": lambda total: \"total_branch_length\",\n",
    "        },\n",
    "        \"num_lineages_by_phenotype_and_time\": {\n",
    "            \"fnc\": utils.num_lineages_by_phenotype_and_time,\n",
    "            \"fnc_args\": [\n",
    "                {\"t\": t}\n",
    "                for t in np.linspace(sim_spec[\"t_min\"], sim_spec[\"t_max\"], num=6)[1:-1]\n",
    "            ],\n",
    "            \"result_keys\": sim_spec[\"state_space\"],\n",
    "            \"result_key_name\": \"phenotype\",\n",
    "            \"default_value\": 0,\n",
    "            \"col_name\": lambda phenotype, t: f\"num_lineages_phenotype={phenotype}_t={t}\",\n",
    "        },\n",
    "        \"num_leaves_by_phenotype\": {\n",
    "            \"fnc\": utils.num_leaves_by_phenotype,\n",
    "            \"fnc_args\": [{}],\n",
    "            \"result_keys\": sim_spec[\"state_space\"],\n",
    "            \"result_key_name\": \"phenotype\",\n",
    "            \"default_value\": 0,\n",
    "            \"col_name\": lambda phenotype: f\"num_leaves_phenotype={phenotype}\",\n",
    "        },\n",
    "        \"branch_length_by_phenotype\": {\n",
    "            \"fnc\": utils.branch_length_by_phenotype,\n",
    "            \"fnc_args\": [{}],\n",
    "            \"result_keys\": [phenotype for phenotype in sim_spec[\"state_space\"]],\n",
    "            \"result_key_name\": \"phenotype\",\n",
    "            \"default_value\": 0,\n",
    "            \"col_name\": lambda phenotype: f\"branch_length_phenotype={phenotype}\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    clade_metric_info = {\n",
    "        \"num_nodes\": {\n",
    "            \"fnc\": utils.clade_sizes_by_phenotype,\n",
    "            \"fnc_args\": [{}],\n",
    "            \"phenotypes\": sim_spec[\"state_space\"],\n",
    "            \"metric_name\": \"number of nodes\",\n",
    "        },\n",
    "        \"branch_length\": {\n",
    "            \"fnc\": utils.clade_lengths_by_phenotype,\n",
    "            \"fnc_args\": [{}],\n",
    "            \"phenotypes\": sim_spec[\"state_space\"],\n",
    "            \"metric_name\": \"branch length\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Run simulations\n",
    "    nonempty_tree_count = 0\n",
    "    for tree_id in tree_ids:\n",
    "        # This is so that we aren't using the same seeds in the\n",
    "        # across modes, which could violate independence assumptions in\n",
    "        # distributional comparisons.\n",
    "        seed = abs(\n",
    "            int(\n",
    "                hashlib.sha256(f'{sim_spec[\"mode\"]}_{tree_id}'.encode()).hexdigest(), 16\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Simulate tree\n",
    "        tree_info = simulate_tree(\n",
    "            seed=seed,\n",
    "            state_space=sim_spec[\"state_space\"],\n",
    "            sampling_probability=sim_spec[\"sampling_probability\"],\n",
    "            init_dist=sim_spec[\"init_dist\"],\n",
    "            birth_process=birth_process,\n",
    "            death_process=death_process,\n",
    "            mutation_process=mutation_process,\n",
    "            mutator=mutator,\n",
    "            t_max=sim_spec[\"t_max\"],\n",
    "            t_min=sim_spec[\"t_min\"],\n",
    "            tree_id=tree_id,\n",
    "            do_prune=do_prune,\n",
    "            min_survivors=sim_spec[\"min_survivors\"],\n",
    "            capacity=sim_spec[\"capacity\"],\n",
    "        )\n",
    "\n",
    "        tree_df, clade_df = compute_metrics(\n",
    "            tree_info=tree_info,\n",
    "            tree_metric_info=tree_metric_info,\n",
    "            clade_metric_info=clade_metric_info,\n",
    "        )\n",
    "        all_trees_df = pd.concat([all_trees_df, tree_df], ignore_index=True)\n",
    "        all_clades_df = pd.concat([all_clades_df, clade_df], ignore_index=True)\n",
    "\n",
    "        if tree_info[\"tree\"] is not None:\n",
    "            nonempty_tree_count += 1\n",
    "            if sim_spec[\"save_tree\"]:\n",
    "                directory_path = pathlib.Path(sim_spec[\"directory\"])\n",
    "                tree_path = (\n",
    "                    directory_path\n",
    "                    / f'{sim_spec[\"mode\"]}'\n",
    "                    / f'trees'\n",
    "                    / f'tree_{tree_id}.nw'\n",
    "                )\n",
    "                tree_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                tree_info[\"tree\"].write(\n",
    "                    format = 1,\n",
    "                    outfile = tree_path,\n",
    "                    features = ['state','t','event'], # all features\n",
    "                    format_root_node = True,\n",
    "                )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f'{sim_spec[\"tag\"]}, tree_id {tree_id + 1}, nonempty tree count: {nonempty_tree_count}/{sim_spec[\"N_trees\"]}, tip count: {tree_df.loc[tree_id,\"pruned tree leaf count\"]}, tree size: {tree_df.loc[tree_id,\"pruned tree size\"]}',\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "\n",
    "        if nonempty_tree_count >= sim_spec[\"N_trees\"]:\n",
    "            break\n",
    "\n",
    "    # Save to file\n",
    "    if save_to_file:\n",
    "        directory_path = pathlib.Path(sim_spec[\"directory\"])\n",
    "\n",
    "        counter = 1\n",
    "        tree_path = (\n",
    "            directory_path\n",
    "            / f'{sim_spec[\"mode\"]}'\n",
    "            / f'tree_metrics_{sim_spec[\"tag\"]}_v{counter}_df.csv'\n",
    "        )\n",
    "        clade_path = (\n",
    "            directory_path\n",
    "            / f'{sim_spec[\"mode\"]}'\n",
    "            / f'clade_metrics_{sim_spec[\"tag\"]}_v{counter}_df.csv'\n",
    "        )\n",
    "\n",
    "        while tree_path.exists() or clade_path.exists():\n",
    "            counter += 1\n",
    "            tree_path = (\n",
    "                directory_path\n",
    "                / f'{sim_spec[\"mode\"]}'\n",
    "                / f'tree_metrics_{sim_spec[\"tag\"]}_v{counter}_df.csv'\n",
    "            )\n",
    "            clade_path = (\n",
    "                directory_path\n",
    "                / f'{sim_spec[\"mode\"]}'\n",
    "                / f'clade_metrics_{sim_spec[\"tag\"]}_v{counter}_df.csv'\n",
    "            )\n",
    "\n",
    "        tree_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        clade_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(\n",
    "            directory_path / f'{sim_spec[\"tag\"]}_v{counter}_specs.json', \"w\"\n",
    "        ) as outfile:\n",
    "            json.dump(sim_spec, outfile, cls=NumpyArrayEncoder)\n",
    "\n",
    "        all_trees_df.to_csv(tree_path, index=False)\n",
    "        all_clades_df.to_csv(clade_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
